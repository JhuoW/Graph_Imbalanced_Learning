Cora:
  epochs: 1000
  add_self_loops: False
  feat_norm: False
  num_layers: 2
  hid_dim: 512
  dropout: 0.5
  learning_rate: 0.01
  weight_decay: 0.0005
  proj: False
  monitor: f1
  patience: 300
# # acc: [0.663, 0.683, 0.717, 0.723, 0.726, 0.689, 0.677, 0.721, 0.658, 0.7]
# # acc: avg / std = 0.6957 / 0.0254
# # f1: [0.5893, 0.618, 0.6762, 0.6726, 0.6621, 0.6351, 0.6133, 0.6825, 0.5672, 0.6527]
# # f1: avg / std = 0.6369 / 0.0392
# # bacc: [0.6057, 0.6303, 0.6798, 0.6673, 0.6605, 0.6551, 0.6415, 0.698, 0.6018, 0.6616]
# # bacc: avg / std = 0.6501 / 0.0307


CiteSeer:
  epochs: 300
  add_self_loops: False
  feat_norm: False
  num_layers: 2
  hid_dim: 256
  dropout: 0.5
  learning_rate: 0.01
  weight_decay: 0.00005
  proj: False
  monitor: f1
  patience: 300
# acc: [0.411, 0.443, 0.371, 0.455, 0.415, 0.455, 0.446, 0.387, 0.445, 0.566]
# acc: avg / std = 0.4394 / 0.0532
# f1: [0.3731, 0.4251, 0.3361, 0.4332, 0.3873, 0.4371, 0.4328, 0.3524, 0.39, 0.5582]
# f1: avg / std = 0.4125 / 0.0623
# bacc: [0.4397, 0.4616, 0.3979, 0.477, 0.4418, 0.483, 0.4639, 0.4111, 0.4504, 0.5767]
# bacc: avg / std = 0.4603 / 0.0489


# PubMed:
#   epochs: 800
#   add_self_loops: False
#   feat_norm: False
#   num_layers: 2
#   hid_dim: 512
#   dropout: 0.5
#   learning_rate: 0.01
#   weight_decay: 0.00005
#   proj: False
#   monitor: f1
#   patience: 300
# # acc: [0.646, 0.602, 0.557, 0.595, 0.602, 0.552, 0.688, 0.667, 0.627, 0.7]
# # acc: avg / std = 0.6236 / 0.0513
# # f1: [0.6205, 0.574, 0.4816, 0.545, 0.5813, 0.4689, 0.6777, 0.6452, 0.62, 0.6891]
# # f1: avg / std = 0.5903 / 0.0754
# # bacc: [0.6929, 0.6466, 0.621, 0.649, 0.6605, 0.6138, 0.7213, 0.708, 0.6868, 0.7352]
# # bacc: avg / std = 0.6735 / 0.0417

PubMed:
  epochs: 800
  add_self_loops: False
  feat_norm: False
  num_layers: 2
  hid_dim: 512
  dropout: 0.5
  learning_rate: 0.01
  weight_decay: 0.00005
  proj: False
  monitor: f1
  patience: 300