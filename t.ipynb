{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1, 0, 2]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.array([[False, True, False],\n",
    "              [True, False, False],\n",
    "              [False, False, True]])\n",
    "np.where(c == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,2,2,3])\n",
    "b = np.array([0,2,2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a == b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import Planetoid\n",
    "import os.path as osp\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "name = 'Cora'\n",
    "path = osp.join('datasets', name)\n",
    "split = 'imbalance'\n",
    "imb_ratio = 10\n",
    "fix_minority = True\n",
    "\n",
    "dataset = Planetoid(path, name, split=split, imb_ratio= imb_ratio, fix_minority= fix_minority, transform = T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "imb_cls_num_list = dataset.imb_cls_num_list\n",
    "# def get_idx_info(data, n_cls):\n",
    "#     train_mask = data.train_mask\n",
    "#     labels = data.y\n",
    "#     index_list = torch.arange(labels.shape[0])  # all node indices\n",
    "#     train_nodes_per_cls = []\n",
    "#     num_train_nodes_per_cls     = []\n",
    "#     for i in range(n_cls):\n",
    "#         cls_indices = index_list[((labels == i) & train_mask)] # all nodes idx with label i\n",
    "#         num_nodes_i = (labels[train_mask] == i).sum()\n",
    "#         train_nodes_per_cls.append(cls_indices)\n",
    "#         num_train_nodes_per_cls.append(int(num_nodes_i.item()))\n",
    "#     return train_nodes_per_cls, num_train_nodes_per_cls\n",
    "\n",
    "\n",
    "def balance_embedding(data, n_cls):\n",
    "    x, edge_index = data.x, data.edge_index\n",
    "    imb_train_mask = data.imb_train_mask\n",
    "    max_num = max(imb_cls_num_list)\n",
    "    imb_cls_num = n_cls // 2\n",
    "\n",
    "    upsamples = np.array(max_num - np.array(imb_cls_num_list)) # [ 0  0  0  0 18 18 18]\n",
    "    print(upsamples)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20, 20, 20, 2, 2, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_cls_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[20, 20, 20, 20, 2, 2, 2],\n",
    "                  [1,  2,  3,  4,  5,  6, 7]], dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4981, 0.4981, 0.4981, 0.4981, 0.0498, 0.0498, 0.0498],\n",
       "        [0.0845, 0.1690, 0.2535, 0.3381, 0.4226, 0.5071, 0.5916]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "F.normalize(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4981, 0.4981, 0.4981, 0.4981, 0.0498, 0.0498, 0.0498],\n",
       "        [0.0845, 0.1690, 0.2535, 0.3381, 0.4226, 0.5071, 0.5916]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / np.linalg.norm(a, axis=1, ord=2, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20., 20., 20., 20.,  2.,  2.,  2.],\n",
       "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1612.,  236.],\n",
       "        [ 236.,  140.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a@ a.t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5, 11],\n",
       "       [11, 25]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([[1,2], [3,4]])\n",
    "b @ b.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0.1, 0.3, 0.2, 0.7, 0.4], \n",
    "              [0.7, 0.5, 0.6, 0.5, 0.3],\n",
    "              [0.3, 0.2, 1.1, 0.1, 1.3],\n",
    "              [0.5, 0.3, 0.2, 0.7, 0.6],\n",
    "              [1.0, 2.2, 0.3, 0.6, 0.2]])\n",
    "\n",
    "np.fill_diagonal(A, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0.3, 0.2, 0.7, 0.4],\n",
       "       [0.7, 0. , 0.6, 0.5, 0.3],\n",
       "       [0.3, 0.2, 0. , 0.1, 1.3],\n",
       "       [0.5, 0.3, 0.2, 0. , 0.6],\n",
       "       [1. , 2.2, 0.3, 0.6, 0. ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([1,1,0,2,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6500, 1.2000, 0.1500, 0.3500, 0.6500],\n",
       "        [0.3500, 0.1500, 0.4000, 0.6000, 0.3500],\n",
       "        [0.5000, 0.3000, 0.2000, 0.0000, 0.6000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "scatter_mean(torch.from_numpy(A), torch.from_numpy(B), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  13,  14,\n",
       "         15,  16,  17,  18,  19,  20,  21,  23,  24,  25,  26,  27,  28,  30,\n",
       "         32,  34,  35,  36,  37,  40,  44,  45,  46,  48,  51,  52,  53,  54,\n",
       "         57,  58,  59,  60,  61,  62,  64,  65,  68,  71,  72,  73,  74,  79,\n",
       "         80,  81,  83,  85,  88,  90,  94,  95,  98, 100, 101, 102, 103, 104,\n",
       "        105, 109, 110, 111, 112, 121, 124, 126, 131, 133, 134, 135, 136, 137,\n",
       "        138, 139])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor(torch.nonzero(data.imb_train_mask, as_tuple=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(-A, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 2, 5: 3, 6: 2}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers_list = [4, 4, 5, 6, 6, 5,5]\n",
    "\n",
    "# Counting the frequency of each number using a dictionary\n",
    "frequency_dict = {}\n",
    "for number in numbers_list:\n",
    "    frequency_dict[number] = frequency_dict.get(number, 0) + 1\n",
    "\n",
    "frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([4, 5, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 in frequency_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(new_train_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = {4: 9, 5:9, 6:9}\n",
    "b = np.array([4,4,5,6,6,5])\n",
    "\n",
    "result = np.array([a[item] for item in b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 9, 9, 9, 9, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.array([31, 97, 65])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.imb_train_mask[c] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.imb_train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(88)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.imb_train_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[3,2,1], [5,6,1],[9,2,10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = np.argsort(-a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [1, 0, 2],\n",
       "       [2, 0, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = [torch.tensor([1,2,3]), torch.tensor([4,5,6]), torch.tensor([7,8,9])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Mean and standard deviation\n",
    "mu, sigma = 0, 1\n",
    "\n",
    "# Generating a range of values from -3 to 3 with 0.001 step\n",
    "x = np.arange(-3, 3, 0.001)\n",
    "\n",
    "# Calculating the normal distribution y values\n",
    "y = (1 / (np.sqrt(2 * np.pi) * sigma)) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "# Creating the plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(x, y)\n",
    "\n",
    "# Removing the top and right spines\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.yaxis.set_visible(False)\n",
    "# Adding titles and labels\n",
    "# plt.title('Normal Distribution')\n",
    "# plt.xlabel('Values')\n",
    "# plt.ylabel('Frequency')\n",
    "\n",
    "# Showing the grid\n",
    "# plt.grid(True)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cls = 6\n",
    "num_minor_cls = n_cls // 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False,  True,  True,  True,  True,  True,\n",
       "        True,  True])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,3,4,4,5,5,6,6,6])\n",
    "b = np.array([4,5,6])\n",
    "\n",
    "np.isin(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 10, 10]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[10] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True, True, True]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[True] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.tensor([0.0501, 0.0000, 0.0000, 0.0000, 0.0000, 0.1514, 0.1550, 0.0532, 0.0482,\n",
    "        0.1060, 0.0000, 0.1351, 0.0808, 0.0000, 0.0655, 0.0018, 0.0304, 0.0367,\n",
    "        0.1430, 0.0000, 0.0000, 0.0552, 0.0000, 0.1345, 0.0000, 0.0971, 0.0000,\n",
    "        0.0000, 0.0106, 0.1130, 0.0536, 0.1379, 0.1555, 0.0000, 0.1556, 0.0399,\n",
    "        0.0000, 0.0000, 0.0942, 0.0000, 0.0000, 0.0075, 0.0000, 0.0652, 0.0000,\n",
    "        0.2378, 0.0000, 0.0000, 0.0000, 0.0190, 0.0000, 0.0000, 0.0402, 0.0431,\n",
    "        0.0264, 0.0000, 0.0000, 0.0773, 0.0000, 0.0000, 0.0000, 0.0000, 0.0022,\n",
    "        0.0309, 0.0000, 0.0000, 0.0000, 0.0000, 0.1825, 0.0173, 0.0392, 0.0000,\n",
    "        0.0000, 0.1303, 0.0000, 0.0000, 0.0000, 0.0933, 0.0000, 0.0000, 0.1578,\n",
    "        0.0409, 0.0000, 0.0609, 0.0438, 0.0000, 0.0748, 0.0000, 0.0000, 0.1184,\n",
    "        0.0395, 0.0000, 0.0000, 0.0770, 0.0501, 0.0682, 0.0000, 0.0586, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0997, 0.0000, 0.0000, 0.0601, 0.1419, 0.0000,\n",
    "        0.1086, 0.0320, 0.0030, 0.0669, 0.0000, 0.0558, 0.0000, 0.0000, 0.0000,\n",
    "        0.0549, 0.0000, 0.0199, 0.1193, 0.0056, 0.0000, 0.0000, 0.0550, 0.0000,\n",
    "        0.0752, 0.0429, 0.0082, 0.0000, 0.0000, 0.0000, 0.0102, 0.0000, 0.0000,\n",
    "        0.1485, 0.0000, 0.0406, 0.0000, 0.0549, 0.0717, 0.0540, 0.0000, 0.0421,\n",
    "        0.0000, 0.0554, 0.0140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.1620, 0.0000, 0.0000, 0.0000, 0.0228, 0.0000, 0.0000, 0.0271,\n",
    "        0.0220, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0424, 0.0669, 0.0574,\n",
    "        0.0292, 0.0000, 0.1687, 0.0000, 0.0807, 0.1002, 0.0000, 0.1643, 0.0000,\n",
    "        0.1164, 0.0000, 0.0455, 0.0000, 0.0000, 0.0000, 0.0000, 0.1716, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0142, 0.0000, 0.0000, 0.0778, 0.0000,\n",
    "        0.0237, 0.0000, 0.0825, 0.0730, 0.0256, 0.0000, 0.0196, 0.0990, 0.1816,\n",
    "        0.0000, 0.0000, 0.0714, 0.0000, 0.0000, 0.0228, 0.0041, 0.0564, 0.0000,\n",
    "        0.0000, 0.0000, 0.0000, 0.0000, 0.0680, 0.0000, 0.1509, 0.1089, 0.0000,\n",
    "        0.0933, 0.0396, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0435, 0.0000,\n",
    "        0.0000, 0.0926, 0.1252, 0.0285, 0.0290, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "        0.0000, 0.0683, 0.0000, 0.0420, 0.0866, 0.0000, 0.0000, 0.0000, 0.0880,\n",
    "        0.0122, 0.0000, 0.0000, 0.0815], device='cuda:0')\n",
    "b = torch.tensor([ 1.8796e-02, -4.4228e-03,  3.2078e-02,  1.9116e-02,  1.4689e-03,\n",
    "         2.0079e-02,  1.2565e-02, -9.4041e-03,  1.7412e-02,  3.9940e-02,\n",
    "        -3.1709e-04,  4.6095e-03, -3.0108e-03,  1.8429e-03,  5.0848e-03,\n",
    "        -1.3498e-03,  9.0720e-03, -2.1476e-03,  3.2465e-02,  1.5836e-02,\n",
    "         4.0824e-02,  1.4351e-02, -3.9492e-03,  1.0651e-02, -5.7140e-03,\n",
    "         3.2214e-02, -1.7783e-03,  6.5357e-02, -3.8771e-03, -9.9892e-04,\n",
    "         5.7998e-02,  2.0355e-02, -5.3977e-03,  5.3222e-02,  1.5943e-03,\n",
    "         1.8727e-02, -9.7003e-03, -4.5360e-03,  3.2876e-03,  4.8972e-03,\n",
    "        -5.7637e-03, -3.5094e-03, -4.9703e-03, -1.5703e-03, -1.9465e-03,\n",
    "        -4.0052e-03,  1.6495e-02,  5.8101e-03,  1.0356e-02, -1.3679e-02,\n",
    "        -1.9200e-03,  1.8529e-02, -6.1412e-03,  2.7708e-03,  1.7562e-02,\n",
    "        -4.3489e-03, -3.6856e-03,  4.7559e-02,  5.7486e-02, -1.0308e-03,\n",
    "         2.4056e-02,  2.7839e-02,  2.0453e-02, -7.2203e-03,  1.9933e-02,\n",
    "        -5.1106e-03, -1.7211e-03,  1.0159e-02, -6.6886e-03, -3.6662e-03,\n",
    "         3.2569e-02, -1.1208e-03, -1.2006e-02,  5.4139e-03, -3.0357e-03,\n",
    "         1.9920e-02,  1.5119e-02, -1.7462e-03,  2.5520e-03,  1.3106e-02,\n",
    "        -5.1338e-03, -5.9698e-03,  2.9439e-03, -4.5611e-03,  1.2630e-02,\n",
    "         3.9600e-02, -3.7227e-04,  8.5397e-03,  4.3944e-02,  3.4378e-02,\n",
    "         3.0293e-02,  3.2925e-02, -1.5223e-03, -1.1940e-04, -9.9277e-03,\n",
    "         2.2107e-02,  2.3735e-02,  2.5518e-02,  1.2901e-02, -4.0795e-03,\n",
    "        -4.0891e-03,  3.2965e-02,  1.7975e-02, -7.2480e-03,  4.3629e-02,\n",
    "         5.7167e-03, -7.0749e-03,  4.9571e-03, -8.6874e-03, -2.4986e-03,\n",
    "        -4.4821e-03,  1.2568e-02, -2.0296e-03,  1.9383e-02,  6.7858e-03,\n",
    "         2.0026e-02, -2.2465e-03,  3.8231e-02,  1.0151e-02,  3.8361e-02,\n",
    "         2.6015e-02,  1.3136e-02, -1.6139e-04, -7.7029e-03, -3.0649e-03,\n",
    "         2.8500e-02, -4.3032e-04, -1.0720e-02, -7.9818e-03,  2.7766e-02,\n",
    "         2.2864e-02,  1.2506e-02, -1.1022e-02,  2.3994e-02, -2.6181e-03,\n",
    "         4.5866e-03,  5.0835e-02, -4.0287e-03,  3.9991e-03, -2.3533e-03,\n",
    "         1.1859e-02,  2.8515e-02,  2.8735e-02, -3.8338e-04,  1.1716e-02,\n",
    "        -6.8708e-04, -6.3349e-04,  2.2435e-02,  1.1844e-02,  1.5340e-02,\n",
    "         1.6792e-03, -4.4893e-03,  5.7045e-02,  3.4212e-03, -4.3182e-03,\n",
    "         3.9871e-03,  3.5535e-04, -8.8043e-03,  2.5101e-02, -9.6015e-03,\n",
    "         1.8918e-02, -2.5986e-03, -6.7061e-03, -1.9832e-03, -6.9586e-03,\n",
    "        -2.6700e-04,  5.2158e-03,  5.1217e-02,  1.4723e-03,  1.7601e-02,\n",
    "         1.6709e-02,  1.0272e-02, -6.1588e-03,  1.7907e-02,  5.4243e-02,\n",
    "         1.5596e-02,  2.8100e-02, -1.0224e-02, -3.1497e-03, -5.0092e-03,\n",
    "         1.2541e-02, -6.9602e-03, -6.2113e-03,  1.6902e-03, -1.4150e-03,\n",
    "        -7.6179e-04,  2.2196e-02,  2.2349e-03,  2.3555e-02,  2.1874e-02,\n",
    "        -6.8529e-06,  1.5048e-02,  2.7873e-03,  1.0025e-02, -2.3042e-03,\n",
    "         1.1096e-02, -9.0425e-03, -1.2090e-02,  2.5262e-02,  1.9502e-02,\n",
    "         3.5535e-02, -4.8110e-03,  5.4671e-02,  7.3383e-03, -7.3827e-04,\n",
    "        -4.5314e-03, -1.2793e-03,  3.2644e-02,  2.5347e-02,  3.8730e-03,\n",
    "         3.1020e-02,  8.6647e-03, -2.1498e-03,  1.4469e-02,  1.5123e-03,\n",
    "         3.4905e-02, -4.5100e-03,  3.1163e-02, -3.3034e-03, -9.7821e-04,\n",
    "        -1.5875e-03,  4.5438e-04, -1.8966e-04,  1.0672e-02, -4.2313e-03,\n",
    "        -2.9077e-03, -3.4665e-03,  2.5006e-02, -9.4382e-03, -8.5704e-03,\n",
    "         2.0049e-02,  2.2265e-02, -7.9969e-04,  8.7048e-03, -4.6602e-03,\n",
    "        -6.5185e-03, -2.9353e-03,  3.4366e-02,  2.9408e-03, -8.0578e-03,\n",
    "         2.1304e-02,  4.4984e-02, -2.5833e-03,  3.8613e-02,  4.0029e-02,\n",
    "         1.1495e-03, -3.3914e-03, -2.3650e-03,  4.2752e-03, -1.5103e-03,\n",
    "        -2.3215e-03,  2.2734e-03,  1.2443e-02,  4.5380e-02,  2.4575e-02,\n",
    "        -3.6184e-03], device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [1,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [7,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [10,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [12,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [15,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [17,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [22,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [24,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [26,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [28,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [29,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [99,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [100,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [103,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [106,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [108,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [109,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [110,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [112,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [116,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [122,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [123,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [124,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [126,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [127,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [65,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [66,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [68,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [69,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [71,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [72,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [74,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [77,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [80,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [81,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [83,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [86,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [92,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [93,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [94,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [32,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [36,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [37,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [40,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [41,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [42,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [43,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [44,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [45,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [49,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [50,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [52,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [55,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [56,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [59,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [63,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m binary_cross_entropy\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/torch/nn/functional.py:3122\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3119\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3120\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.functional import binary_cross_entropy\n",
    "binary_cross_entropy(a, b, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
